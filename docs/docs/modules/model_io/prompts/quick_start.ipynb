{
 "cells": [
  {
   "cell_type": "raw",
   "id": "77dd0c90-94d7-4acd-a360-e977b39d0a8f",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 0\n",
    "title: Quick reference\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98412d-fc53-42c1-aed8-f1f8eb9ada58",
   "metadata": {},
   "source": [
    "# Quick reference\n",
    "\n",
    "Prompt templates are predefined recipes for generating prompts for language models.\n",
    "\n",
    "A template may include instructions, few-shot examples, and specific context and\n",
    "questions appropriate for a given task.\n",
    "\n",
    "LangChain provides tooling to create and work with prompt templates.\n",
    "\n",
    "LangChain strives to create model agnostic templates to make it easy to reuse\n",
    "existing templates across different language models.\n",
    "\n",
    "Typically, language models expect the prompt to either be a string or else a list of chat messages.\n",
    "\n",
    "## `PromptTemplate`\n",
    "\n",
    "Use `PromptTemplate` to create a template for a string prompt.\n",
    "\n",
    "By default, `PromptTemplate` uses [Python's str.format](https://docs.python.org/3/library/stdtypes.html#str.format)\n",
    "syntax for templating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5bc258b-87d2-486b-9785-edf5b23fd179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c803c-0f80-412d-9156-b8390e0265c0",
   "metadata": {},
   "source": [
    "The template supports any number of variables, including no variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bd7ac3-5cf6-4eb2-8205-d1a01029b56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke\")\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715fd80-e294-49ca-9fc2-5a012949ed8a",
   "metadata": {},
   "source": [
    "You can create custom prompt templates that format the prompt in any way you want.\n",
    "For more information, see [Prompt Template Composition](./composition).\n",
    "\n",
    "## `ChatPromptTemplate`\n",
    "\n",
    "The prompt to [chat models](../chat) is a list of [chat messages](/docs/modules/model_io/chat/message_types).\n",
    "\n",
    "Each chat message is associated with content, and an additional parameter called `role`.\n",
    "For example, in the OpenAI [Chat Completions API](https://platform.openai.com/docs/guides/chat/introduction), a chat message can be associated with an AI assistant, a human or a system role.\n",
    "\n",
    "Create a chat prompt template like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d088d53c-0e20-4fb9-9d54-b0e989b998b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee13f0",
   "metadata": {},
   "source": [
    "Piping these formatted messages into LangChain's `ChatOpenAI` chat model class is roughly equivalent to the following with using the OpenAI client directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49aebba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI bot. Your name is Bob.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, how are you doing?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"I'm doing well, thanks!\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is your name?\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7e3ef-ba7d-4ca5-a95c-a0488c9679e5",
   "metadata": {},
   "source": [
    "The `ChatPromptTemplate.from_messages` static method accepts a variety of message representations and is a convenient way to format input to chat models with exactly the messages you want.\n",
    "\n",
    "For example, in addition to using the 2-tuple representation of (type, content) used\n",
    "above, you could pass in an instance of `MessagePromptTemplate` or `BaseMessage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6632eda-582f-4f29-882f-108587f0397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"), HumanMessage(content=\"I don't like eating tasty things\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to \"\n",
    "                \"sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(text=\"I don't like eating tasty things\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b46da-d51b-4801-955f-ba4bf139162f",
   "metadata": {},
   "source": [
    "This provides you with a lot of flexibility in how you construct your chat prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305b5ae",
   "metadata": {},
   "source": [
    "## Message Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8513963e",
   "metadata": {},
   "source": [
    "LangChain provides different types of `MessagePromptTemplate`. The most commonly used are `AIMessagePromptTemplate`, `SystemMessagePromptTemplate` and `HumanMessagePromptTemplate`, which create an AI message, system message and human message respectively. You can read more about the [different types of messages here](/docs/modules/model_io/chat/message_types).\n",
    "\n",
    "In cases where the chat model supports taking chat message with arbitrary role, you can use `ChatMessagePromptTemplate`, which allows user to specify the role name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71aab8e7-3236-43b6-b516-a76a6cfdc39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='May the force be with you', role='Jedi')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"May the {subject} be with you\"\n",
    "\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(\n",
    "    role=\"Jedi\", template=prompt\n",
    ")\n",
    "chat_message_prompt.format(subject=\"force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe2a21-c893-46cf-9fc7-a7f90c09695a",
   "metadata": {},
   "source": [
    "## `MessagesPlaceholder`\n",
    "\n",
    "LangChain also provides `MessagesPlaceholder`, which gives you full control of what messages to be rendered during formatting. This can be useful when you are uncertain of what role you should be using for your message prompt templates or when you wish to insert a list of messages during formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a3e39d-7c7e-4a89-80a7-74ea4e6cf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "human_prompt = \"Summarize our conversation so far in {word_count} words.\"\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [MessagesPlaceholder(variable_name=\"conversation\"), human_message_template]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a92fd952-d96f-4606-8a50-6077ea8ddef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the best way to learn programming?'),\n",
       " AIMessage(content='1. Choose a programming language: Decide on a programming language that you want to learn.\\n\\n2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.\\n\\n3. Practice, practice, practice: The best way to learn programming is through hands-on experience'),\n",
       " HumanMessage(content='Summarize our conversation so far in 10 words.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "human_message = HumanMessage(content=\"What is the best way to learn programming?\")\n",
    "ai_message = AIMessage(\n",
    "    content=\"\"\"\\\n",
    "1. Choose a programming language: Decide on a programming language that you want to learn.\n",
    "\n",
    "2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.\n",
    "\n",
    "3. Practice, practice, practice: The best way to learn programming is through hands-on experience\\\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chat_prompt.format_prompt(\n",
    "    conversation=[human_message, ai_message], word_count=\"10\"\n",
    ").to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86202814-3539-4a94-8698-73426240516e",
   "metadata": {},
   "source": [
    "The full list of message prompt template types includes:\n",
    "\n",
    "* [AIMessagePromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.AIMessagePromptTemplate.html), for AI assistant messages;\n",
    "* [SystemMessagePromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.SystemMessagePromptTemplate.html), for system messages;\n",
    "* [HumanMessagePromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.HumanMessagePromptTemplate.html), for user messages;\n",
    "* [ChatMessagePromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html), for messages with arbitrary roles;\n",
    "* [MessagesPlaceholder](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html), which accommodates a list of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68e9ae",
   "metadata": {},
   "source": [
    "## LCEL\n",
    "\n",
    "`PromptTemplate` and `ChatPromptTemplate` implement the [Runnable interface](/docs/expression_language/interface), the basic building block of the [LangChain Expression Language (LCEL)](/docs/expression_language/). This means they support `invoke`, `ainvoke`, `stream`, `astream`, `batch`, `abatch`, `astream_log` calls.\n",
    "\n",
    "`PromptTemplate` accepts a dictionary (of the prompt variables) and returns a `StringPromptValue`. A `ChatPromptTemplate` accepts a dictionary and returns a `ChatPromptValue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2e02bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me a funny joke about chickens.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "prompt_val = prompt_template.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n",
    "prompt_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60a44b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_val.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1366e47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me a funny joke about chickens.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_val.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e335131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to \"\n",
    "                \"sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_val = chat_template.invoke({\"text\": \"i dont like eating tasty things.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44924df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"),\n",
       " HumanMessage(content='i dont like eating tasty things.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_val.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a313f987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: You are a helpful assistant that re-writes the user's text to sound more upbeat.\\nHuman: i dont like eating tasty things.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_val.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e59ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
